{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pk\n",
    "from itertools import tee\n",
    "from math import ceil\n",
    "import statistics\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = os.path.join(os.path.pardir, \"logs\", \"GIN\")\n",
    "DEEP_CHEM = \"DeepChem_20200707\"\n",
    "JAK123 = \"JAK123_20200706\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Renamer:\n",
    "    def __init__(self):\n",
    "        self.required_fields = [\"data_ratio\", \"encoder_dataset\", \"classifier_dataset\", \"encoder_epochs\"]\n",
    "\n",
    "    def rename_result(self, path):\n",
    "        conf_file = os.path.join(path, \"configs.yml\")\n",
    "        try:\n",
    "            configs = yaml.load(open(conf_file, \"r\"), Loader=yaml.FullLoader)\n",
    "        except FileNotFoundError:\n",
    "            return\n",
    "        new_name = \"\"\n",
    "        for key, value in configs.items():\n",
    "            if not key in self.required_fields: continue\n",
    "            if isinstance(value, list):\n",
    "                value = \"-\".join(map(str,value))\n",
    "            if new_name == \"\":\n",
    "                new_name += str(value)\n",
    "            else:\n",
    "                new_name += \"_\" + str(value)\n",
    "        counter = 1\n",
    "        while 1:\n",
    "            try:\n",
    "                os.rename(path, os.path.join(os.path.dirname(path), new_name))\n",
    "                break\n",
    "            except FileExistsError:\n",
    "                counter += 1\n",
    "                new_name += \"_\" + str(value) + \"_\" + str(counter)\n",
    "    \n",
    "    def rename_results(self, path):\n",
    "        results = os.scandir(path)\n",
    "        for res in results:\n",
    "            if not res.is_dir():\n",
    "                continue\n",
    "            self.rename_result(res.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] The directory name is invalid: '..\\\\logs\\\\GIN\\\\DeepChem_20200707\\\\20200707_011659\\\\bace_roc.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a942d36ec117>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mROOT_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m             \u001b[0mrn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-509a1ea4943c>\u001b[0m in \u001b[0;36mrename_results\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrename_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] The directory name is invalid: '..\\\\logs\\\\GIN\\\\DeepChem_20200707\\\\20200707_011659\\\\bace_roc.png'"
     ]
    }
   ],
   "source": [
    "rn = Renamer()\n",
    "for folder in [DEEP_CHEM, JAK123]:\n",
    "    for date in os.scandir(os.path.join(ROOT_PATH, folder)):\n",
    "        for task in os.scandir(date.path):\n",
    "            rn.rename_results(task.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dude vs ZINC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparer:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 path1=None,\n",
    "                 path2=None,\n",
    "                 metric=\"validating_AP_AUC\",\n",
    "                 metric_fname=\"classifier_metrics.pk\",\n",
    "                 config_fname=\"configs.yml\"):\n",
    "        self._path1 = path1\n",
    "        self._path2 = path2\n",
    "        self.metric = metric\n",
    "        self.metric_fname = metric_fname\n",
    "        self.config_fname = config_fname\n",
    "    \n",
    "    @property\n",
    "    def path1(self):\n",
    "        return self._path1\n",
    "    \n",
    "    @path1.setter\n",
    "    def path1(self, value):\n",
    "        assert os.path.exists(value)\n",
    "        self._path1 = value\n",
    "        \n",
    "    @property\n",
    "    def path2(self):\n",
    "        return self._path2\n",
    "    \n",
    "    @path2.setter\n",
    "    def path2(self, value):\n",
    "        assert os.path.exists(value)\n",
    "        self._path2 = value\n",
    "    \n",
    "    def _get_pairs(self):\n",
    "        dirs1 = os.scandir(self.path1)\n",
    "        dirs2 = os.scandir(self.path2)\n",
    "        marks1 = dict()\n",
    "        marks2 = dict()\n",
    "        for d in dirs1:\n",
    "            if d.is_dir():\n",
    "                tokens = d.name.split(\"_\")\n",
    "                ratio = tokens[1]\n",
    "                encoder_epochs = tokens[-1]\n",
    "                marks1[f\"{ratio}_{encoder_epochs}\"] = d.path\n",
    "        for d in dirs2:\n",
    "            if d.is_dir():\n",
    "                tokens = d.name.split(\"_\")\n",
    "                ratio = tokens[1]\n",
    "                encoder_epochs = tokens[-1]\n",
    "                marks2[f\"{ratio}_{encoder_epochs}\"] = d.path\n",
    "        pairs = list()\n",
    "        for m, v in marks1.items():\n",
    "            pairs.append((v, marks2[m]))\n",
    "        return pairs\n",
    "    \n",
    "    def _number_of_rows(self, nplots, ncols):\n",
    "        return int(ceil(nplots / ncols))\n",
    "        \n",
    "    def compare(self, ncols=2, figsize=[16, 12], ylim=[0, 1]):\n",
    "        pairs = self._get_pairs()\n",
    "        nr = self._number_of_rows(len(pairs), ncols)\n",
    "        fig, axes = plt.subplots(ncols=ncols, nrows=nr, figsize=figsize)\n",
    "        fig.tight_layout(pad=3.0)\n",
    "        for pair, axe in zip(pairs, axes.flatten()):\n",
    "            met1 = pk.load(open(os.path.join(pair[0], self.metric_fname), \"rb\"))[self.metric]\n",
    "            met2 = pk.load(open(os.path.join(pair[1], self.metric_fname), \"rb\"))[self.metric]\n",
    "            conf1 = yaml.load(open(os.path.join(pair[0], self.config_fname), \"r\"), Loader=yaml.FullLoader)\n",
    "            conf2 = yaml.load(open(os.path.join(pair[1], self.config_fname), \"r\"), Loader=yaml.FullLoader)\n",
    "            axe.plot(list(range(len(met1))), met1, label=f\"{'_'.join(conf1['encoder_dataset'])}_{self.metric}\")\n",
    "            axe.plot(list(range(len(met2))), met2, label=f\"{'_'.join(conf2['encoder_dataset'])}_{self.metric}\")\n",
    "            axe.set_ylim(ylim)\n",
    "            axe.legend()\n",
    "            axe.set_title(f\"Ratio: {conf1['data_ratio'][0]}, Encoder: {bool(conf1['encoder_epochs'])}, {'_'.join(conf1['encoder_dataset'])} vs {'_'.join(conf2['encoder_dataset'])}\")\n",
    "            axe.grid(axis=\"y\")\n",
    "        return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3910daaa8a47474c8ffc8fd5e36ef1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = Comparer(metric=\"validating_AP_AUC\")\n",
    "c.path1 = os.path.join(ROOT_PATH, JAK123, \"20200706_181605\", \"JAK1Dude\")\n",
    "c.path2 = os.path.join(ROOT_PATH, JAK123, \"20200706_181605\", \"ZINC1k\")\n",
    "fig, _ = c.compare(ylim=[0.8, 1])\n",
    "fig.savefig(os.path.join(ROOT_PATH, JAK123, os.path.basename(c.path1)+\"_\"+os.path.basename(c.path2)+\"_\"+c.metric))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6460a592ac4cb68975230957921e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff2f4f90c144a5893c033fc6c3511e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for met in [\"validating_F1\", \"validating_AP_AUC\"]:\n",
    "    c = Comparer(metric=met)\n",
    "    c.path1 = os.path.join(ROOT_PATH, JAK123, \"20200706_154014\", \"JAK3Dude\")\n",
    "    c.path2 = os.path.join(ROOT_PATH, JAK123, \"20200706_154014\", \"ZINC1k\")\n",
    "    fig, _ = c.compare(ylim=[0.4, 1])\n",
    "    fig.savefig(os.path.join(ROOT_PATH, JAK123, os.path.basename(c.path1)+\"_\"+os.path.basename(c.path2)+\"_\"+c.metric))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6408d749c56c424283af56f1e30e946b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8647368e5cbe4bb7a90daa72cb8b1da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for met in [\"validating_F1\", \"validating_AP_AUC\"]:\n",
    "    c = Comparer(metric=met)\n",
    "    c.path1 = os.path.join(ROOT_PATH, JAK123, \"20200706_154006\", \"JAK2\")\n",
    "    c.path2 = os.path.join(ROOT_PATH, JAK123, \"20200706_154006\", \"ZINC1k\")\n",
    "    fig, _ = c.compare(ylim=[0.4, 1])\n",
    "    fig.savefig(os.path.join(ROOT_PATH, JAK123, os.path.basename(c.path1)+\"_\"+os.path.basename(c.path2)+\"_\"+c.metric))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyzer:\n",
    "    \n",
    "    def __init__(self, root, metric=\"validating_AP_AUC\", metric_fname=\"classifier_metrics.pk\"):\n",
    "        self.root = root\n",
    "        self.metric = metric\n",
    "        self.metric_fname = metric_fname\n",
    "        self._header_written = False\n",
    "        \n",
    "    @property\n",
    "    def groups(self):\n",
    "        try:\n",
    "            return self._groups\n",
    "        except AttributeError:\n",
    "            self._groups = self.find_groups()\n",
    "            return self._groups\n",
    "        \n",
    "    def find_groups(self):\n",
    "        dirs = os.scandir(self.root)\n",
    "        groups = set()\n",
    "        for dir_ in dirs:\n",
    "            name = os.path.basename(dir_.path)\n",
    "            base_name = \"_\".join(name.split(\"_\")[:-1])\n",
    "            groups.add(base_name)\n",
    "        return sorted(list(groups))\n",
    "    \n",
    "    def _number_of_rows(self, nplots, ncols):\n",
    "        return int(ceil(nplots / ncols))\n",
    "\n",
    "    def plot_results(self, ncols=4, figsize=[16, 12], ylim=[0, 1]):\n",
    "        groups = self.groups\n",
    "        modes = [\"origin\", \"additive\", \"scaled\"]\n",
    "        nr = self._number_of_rows(len(groups), ncols)\n",
    "        fig, axes = plt.subplots(ncols=ncols, nrows=nr, figsize=figsize)\n",
    "        fig.tight_layout(pad=3.0)\n",
    "        for grp, axe in zip(groups, axes.flatten()[:len(groups)]):\n",
    "            for mod in modes:\n",
    "                with open(os.path.join(self.root, f\"{grp}_{mod}\", self.metric_fname), \"rb\") as f:\n",
    "                    metric = pk.load(f)[self.metric]\n",
    "                label_name = f\"{self.metric}_{mod}\"\n",
    "                axe.plot(list(range(len(metric))), metric, label=label_name)\n",
    "            axe.set_ylim(ylim)\n",
    "            axe.legend()\n",
    "            axe.set_title(grp)\n",
    "            axe.grid(axis=\"y\")\n",
    "        return fig, axes\n",
    "    \n",
    "    def _write_header(self, outf, metrics):\n",
    "        if self._header_written:\n",
    "            return\n",
    "        outf.write(\"group_mode,\")\n",
    "        outf.write(\",\".join([key for key in metrics.keys() if \"loss\" not in key]))\n",
    "        outf.write(\"\\n\")\n",
    "        self._header_written = True\n",
    "        \n",
    "    def _find_best(self, metric):\n",
    "        return statistics.mean(sorted(metric)[-5:])\n",
    "    \n",
    "    def _analysis_metrics(self, metrics, group, mode):\n",
    "        outf = open(os.path.join(self.root, \"statistics.csv\"), \"a\")\n",
    "        self._write_header(outf, metrics)\n",
    "        outf.write(f\"{group}_{mode}\")\n",
    "        for key, metric in metrics.items():\n",
    "            if \"loss\" in key:\n",
    "                continue\n",
    "            best_avg = self._find_best(metric)\n",
    "            outf.write(f\",{best_avg}\")\n",
    "        outf.write(\"\\n\")\n",
    "        outf.close()\n",
    "    \n",
    "    def results_statistics(self, mode=\"scaled\"):\n",
    "        groups = self.groups\n",
    "        for grp in groups:\n",
    "            with open(os.path.join(self.root, f\"{grp}_{mode}\", self.metric_fname), \"rb\") as f:\n",
    "                metrics = pk.load(f)\n",
    "            self._analysis_metrics(metrics, grp, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('playground': conda)",
   "language": "python",
   "name": "python36964bitplaygroundconda3a42ba2689cb4827a840ce2c3efb16bd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
